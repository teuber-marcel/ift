{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "087469ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 60\n",
    "%matplotlib inline\n",
    "import pyift.pyift as ift\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.grid'] = False\n",
    "import torch\n",
    "from flim.experiments import utils, LIDSDataset, ToTensor\n",
    "from flim.models.lcn import LCNCreator\n",
    "import cv2 as cv\n",
    "import torch.nn.functional as F\n",
    "from torchvision    import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from torchsummary import summary\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "import skimage.measure\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f5273",
   "metadata": {},
   "source": [
    "# Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64e435f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, pos_prob, neg_prob):\n",
    "\n",
    "        distance_1 = F.pairwise_distance(anchor, positive, keepdim = True)\n",
    "        distance_2 = F.pairwise_distance(anchor, negative, keepdim = True)\n",
    "\n",
    "        triplet_loss = (F.relu(torch.mul(distance_1, pos_prob) - torch.mul(distance_2, neg_prob) + self.margin)).mean()\n",
    "        acc = (distance_1 < distance_2).sum() * 1.0 / distance_1.size()[0]\n",
    "\n",
    "        return triplet_loss, acc\n",
    "    \n",
    "class TripletLossWithPairMining(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(TripletLossWithPairMining, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, pos_prob, neg_prob):\n",
    "\n",
    "        distance_1 = F.pairwise_distance(anchor, positive, keepdim = True)\n",
    "        distance_2 = F.pairwise_distance(anchor, negative, keepdim = True)\n",
    "        \n",
    "        # semi-hard mining\n",
    "        mask = (distance_2 < (distance_1 + self.margin)) * (distance_2 > (distance_1))\n",
    "        \n",
    "        # hard mining\n",
    "        #mask = (distance_2 < (distance_1))\n",
    "        \n",
    "        triplet_loss = (F.relu(torch.mul(distance_1, pos_prob) - \n",
    "                               torch.mul(distance_2, neg_prob) + self.margin) * mask).mean()\n",
    "        \n",
    "        \n",
    "        acc = (distance_1 < distance_2).sum() * 1.0 / distance_1.size()[0]\n",
    "\n",
    "        return triplet_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae687e",
   "metadata": {},
   "source": [
    "# Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "231fe19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "def set_debug_mode(mode):\n",
    "    global debug\n",
    "    debug = mode\n",
    "\n",
    "def dprint(msg):\n",
    "    if debug: print(msg)\n",
    "\n",
    "def valid_voxel(img, v):\n",
    "    return 0 <= v.x <= (img.xsize - 1) and 0 <= v.y <= (img.ysize - 1)\n",
    "\n",
    "def find_valid_neighbour(img, anchor, same_label, adj_radius):\n",
    "    A = ift.Circular(adj_radius)\n",
    "    p = img.GetCoordIndex(anchor[0], anchor[1], 0)\n",
    "    u = img.GetVoxel(p)\n",
    "    for i in random.sample(range(1, A.n), A.n - 1):\n",
    "        v = ift.GetAdjacentVoxel(A, u, i)\n",
    "        if valid_voxel(img, v):\n",
    "            q = img.GetVoxelIndex(v)\n",
    "            if (img[p] == img[q]) == same_label: # XNOR\n",
    "                return [v.x, v.y], ((v.x - u.x) ** 2 + (v.y - u.y) ** 2) ** 0.5\n",
    "    dprint([u.x, u.y])\n",
    "    return [u.x, u.y], 1\n",
    "\n",
    "def get_prob_from_pixel(pmap, coord):\n",
    "    return pmap[coord[1], coord[0]]\n",
    "\n",
    "\n",
    "class DeepDynamicTreesDataset(Dataset):\n",
    "    def __init__(self, path, nitems, csv=\"files.csv\", radius_adj=5, ext_img=\"png\", ext_label=\"png\",\n",
    "                 use_prob_map=True, prob_tresh=0.97):\n",
    "        dprint(\"Creating Dataset...\")\n",
    "        self.path = path\n",
    "        self.csv = csv\n",
    "        self.nitems = nitems\n",
    "        self.ext_img = ext_img\n",
    "        self.ext_label = ext_label\n",
    "        self.radius_adj = radius_adj\n",
    "        self.count_epochs = 0\n",
    "        self.use_prob_map = use_prob_map\n",
    "        self.prob_tresh = prob_tresh\n",
    "\n",
    "        self.imgs = {\"name\": [],\n",
    "                     \"orig\": [],\n",
    "                     \"tensors\": [],\n",
    "                     \"labels\": [],\n",
    "                     \"markers_file\": {\"fg_seeds\": [], \"bg_seeds\": []},\n",
    "                     \"test_markers\" : [],\n",
    "                     \"prob_map\": {'fg': [], 'bg': []}}\n",
    "\n",
    "        file_csv = open(f\"{path}/{csv}\",\"r\")\n",
    "        self.imgs[\"name\"] = [img.strip() for img in file_csv]\n",
    "\n",
    "        dprint(\"Loading images...\")\n",
    "        self.read_images()\n",
    "        self.read_images_as_features()\n",
    "        dprint(\"Loading labels...\")\n",
    "        self.read_labels()\n",
    "        dprint(\"Loading markers from files...\")\n",
    "        self.read_markers_file()\n",
    "\n",
    "        self.items = []\n",
    "\n",
    "        self.next_epoch(None)\n",
    "\n",
    "    def calculate_probability_map(self, model):\n",
    "        dprint(\"Calculating probability map...\")\n",
    "        self.imgs['prob_map']['fg'].clear()\n",
    "        self.imgs['prob_map']['bg'].clear()\n",
    "\n",
    "        if model is not None:\n",
    "            device = next(model.parameters()).device\n",
    "        for i in range(len(self.imgs['name'])):\n",
    "            imag = self.imgs['orig'][i]\n",
    "            seed = self.imgs['test_markers'][i]\n",
    "            mimg = None\n",
    "            if model is not None:\n",
    "                x = self.imgs['tensors'][i].to(device)\n",
    "                _feat = model(x)\n",
    "                mimg = ift.CreateMImageFromNumPy(np.ascontiguousarray(_feat.squeeze(0).permute(1,2,0).detach().cpu().numpy()))\n",
    "            else:\n",
    "                mimg = ift.ImageToMImage(imag, ift.LABNorm_CSPACE)\n",
    "            wmap = ift.DTRootWeightsMap(mimg, ift.Circular(1.0), seed, 0, False).AsNumPy()\n",
    "            wmap = np.squeeze(wmap, 0)\n",
    "            wmap = np.squeeze(wmap, 2)\n",
    "            labl = ift.DynTreeRoot(mimg, ift.Circular(1.0), seed, 0, 0, None, 0)\n",
    "            labl = labl.AsNumPy()\n",
    "\n",
    "            _max = np.max(wmap)\n",
    "            pmap = (_max - wmap) / (_max + wmap)\n",
    "            pmap = np.where(pmap > self.prob_tresh, pmap, 0)\n",
    "            pmfg = np.where(labl != 0, pmap, 0)\n",
    "            pmbg = np.where(labl == 0, pmap, 0)\n",
    "\n",
    "            self.imgs['prob_map']['fg'].append(pmfg)\n",
    "            self.imgs['prob_map']['bg'].append(pmbg)\n",
    "            self.set_pseudo_markers(i)\n",
    "            \n",
    "\n",
    "    def read_images(self):\n",
    "        for name in self.imgs[\"name\"]:\n",
    "            orig_path = f\"{self.path}/orig/{name}.{self.ext_img}\"\n",
    "            orig = ift.ReadImageByExt(orig_path)\n",
    "            self.imgs[\"orig\"].append(orig)\n",
    "\n",
    "    def read_images_as_features(self):\n",
    "        for name in self.imgs[\"name\"]:\n",
    "            orig_path = f\"{self.path}/orig/{name}.{self.ext_img}\"\n",
    "            img = cv.imread(orig_path)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            img = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.0, 0.0, 0.0], [1.0, 1.0, 1.0])\n",
    "            ])(img)\n",
    "            img_tensor = img.unsqueeze(0)\n",
    "            self.imgs[\"tensors\"].append(img_tensor)\n",
    "\n",
    "\n",
    "    def read_labels(self):\n",
    "        for name in self.imgs[\"name\"]:\n",
    "            gt_path = f\"{self.path}/labels/{name}.{self.ext_label}\"\n",
    "            gt = cv.imread(gt_path, 0)\n",
    "            gt = ift.CreateImageFromNumPy(np.int32(gt), False)\n",
    "            self.imgs[\"labels\"].append(gt)\n",
    "\n",
    "    def read_markers_file(self):\n",
    "        for i, name in enumerate(self.imgs[\"name\"]):\n",
    "            markers_path = f\"{self.path}/markers/{name}.txt\"\n",
    "            img = self.imgs[\"orig\"][i]\n",
    "            seeds = ift.ReadSeeds(img, markers_path)\n",
    "            sdict = seeds.AsDict()\n",
    "            fg_seeds = [[img.GetVoxel(int(k)).x, img.GetVoxel(int(k)).y] for k, v in sdict.items() if v != 0]\n",
    "            bg_seeds = [[img.GetVoxel(int(k)).x, img.GetVoxel(int(k)).y] for k, v in sdict.items() if v == 0]\n",
    "            self.imgs[\"markers_file\"][\"fg_seeds\"].append(fg_seeds)\n",
    "            self.imgs[\"markers_file\"][\"bg_seeds\"].append(bg_seeds)\n",
    "            self.imgs[\"test_markers\"].append(seeds)\n",
    "\n",
    "    def set_pseudo_markers(self, i):\n",
    "        fg, bg = self.imgs['prob_map']['fg'][i], self.imgs['prob_map']['bg'][i]\n",
    "        bg = np.int32(np.where(bg != 0, 1, 0))\n",
    "        bg = ift.CreateImageFromNumPy(bg, False)\n",
    "        fg = np.int32(np.where(fg != 0, 2, 0))\n",
    "        fg = ift.CreateImageFromNumPy(fg, False)\n",
    "        fg_seeds = np.int32(ift.MaskImageToSet(fg, None)[0].AsNumPy())\n",
    "        bg_seeds = np.int32(ift.MaskImageToSet(bg, None)[0].AsNumPy())\n",
    "        fg_seeds = [[fg.GetVoxel(int(s)).x, fg.GetVoxel(int(s)).y] for s in fg_seeds]\n",
    "        bg_seeds = [[bg.GetVoxel(int(s)).x, bg.GetVoxel(int(s)).y] for s in bg_seeds]\n",
    "        self.imgs[\"markers_file\"][\"fg_seeds\"][i] = fg_seeds\n",
    "        self.imgs[\"markers_file\"][\"bg_seeds\"][i] = bg_seeds\n",
    "\n",
    "\n",
    "    def next_epoch(self, model):\n",
    "        dprint(\"Loading next epoch...\")\n",
    "        if self.use_prob_map:\n",
    "            self.calculate_probability_map(model)\n",
    "        self.items.clear()\n",
    "        self.count_epochs += 1\n",
    "\n",
    "        files_len = len(self.imgs[\"name\"])\n",
    "\n",
    "        bg_set = self.imgs[\"markers_file\"][\"bg_seeds\"]\n",
    "        fg_set = self.imgs[\"markers_file\"][\"fg_seeds\"]\n",
    "\n",
    "        nitems_per_file = int(self.nitems / files_len)\n",
    "\n",
    "        # Triplets mining\n",
    "        for ix in range(0, files_len):\n",
    "            for _ in range(0, nitems_per_file, 2):\n",
    "                # foreground anchor sampling\n",
    "                anchor = random.choice(fg_set[ix])\n",
    "                positive, _ = find_valid_neighbour(self.imgs[\"labels\"][ix], anchor, True, self.radius_adj)\n",
    "                negative = random.choice(bg_set[ix])\n",
    "\n",
    "                if not self.use_prob_map:\n",
    "                    neg_prob = pos_prob = 1\n",
    "                else:\n",
    "                    pos_prob = get_prob_from_pixel(self.imgs['prob_map']['fg'][ix], positive)+0.0001\n",
    "                    neg_prob = get_prob_from_pixel(self.imgs['prob_map']['bg'][ix], negative)+0.0001\n",
    "                self.items.append([ix, anchor, positive, negative, pos_prob, neg_prob])\n",
    "\n",
    "                # background anchor sampling\n",
    "                anchor   = random.choice(bg_set[ix])\n",
    "                positive, _ = find_valid_neighbour(self.imgs[\"labels\"][ix], anchor, True, self.radius_adj)\n",
    "                negative = random.choice(fg_set[ix])\n",
    "\n",
    "                if not self.use_prob_map:\n",
    "                    neg_prob = pos_prob = 1\n",
    "                else:\n",
    "                    pos_prob = get_prob_from_pixel(self.imgs['prob_map']['bg'][ix], positive)+0.0001\n",
    "                    neg_prob = get_prob_from_pixel(self.imgs['prob_map']['fg'][ix], negative)+0.0001\n",
    "                self.items.append([ix, anchor, positive, negative, pos_prob, neg_prob])\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        ix, anchor, positive, negative, pos_prob, neg_prob = self.items[ix]\n",
    "        return ix, anchor, positive, negative, pos_prob, neg_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b7691",
   "metadata": {},
   "source": [
    "# Qualitative and Quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07df9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_with_dynamic(ix, dataset:DeepDynamicTreesDataset, features=None):\n",
    "    mimg = None\n",
    "    seeds = dataset.imgs[\"test_markers\"][ix]\n",
    "    if features is not None:\n",
    "        mimg = ift.CreateMImageFromNumPy(np.ascontiguousarray(features.squeeze(0).permute(1,2,0).detach().cpu().numpy()))\n",
    "    else:\n",
    "        img = dataset.imgs[\"orig\"][ix]\n",
    "        mimg = ift.ImageToMImage(img, ift.LABNorm_CSPACE)\n",
    "\n",
    "    A = ift.Circular(1.0)\n",
    "    label = ift.DynTreeRoot(mimg, A, seeds, 0, 0, None, 0)\n",
    "    \n",
    "    gt = dataset.imgs[\"labels\"][ix]\n",
    "    dice = ift.DiceSimilarity(gt, label)\n",
    "    assd = ift.ASSD(gt, label)\n",
    "\n",
    "    return dice, assd, label\n",
    "\n",
    "\n",
    "def segment(ix, dataset, features=None):\n",
    "    dice, assd, label = segment_with_dynamic(ix, dataset, features)\n",
    "    return dice, assd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9f073",
   "metadata": {},
   "source": [
    "# Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7abec902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, model, data, optimizer, criterion):\n",
    "    ix, u, v, w, dp, dn = [t for t in data]\n",
    "    n = len(ix)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    reduced_features = model(x)\n",
    "\n",
    "    anchors   = torch.stack([reduced_features[ix[i],:,int(u[1][i]),int(u[0][i])] for i in range(n)]).to(device)\n",
    "    positives = torch.stack([reduced_features[ix[i],:,int(v[1][i]),int(v[0][i])] for i in range(n)]).to(device)\n",
    "    negatives = torch.stack([reduced_features[ix[i],:,int(w[1][i]),int(w[0][i])] for i in range(n)]).to(device)\n",
    "    dpv       = dp.to(device)\n",
    "    dnv       = dn.to(device)\n",
    "\n",
    "\n",
    "    loss, acc = criterion(anchors, positives, negatives, dpv, dnv)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00412c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletLoss(2.0)\n",
    "\n",
    "def finish_epoch(dataset, model):\n",
    "    dataset.next_epoch(model)\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "def improve_model_for_file(dataset, model, nepochs):\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    dataloader = finish_epoch(dataset, None)\n",
    "    x = torch.cat(dataset.imgs[\"tensors\"],0).to(device)\n",
    "    \n",
    "    for epoch in range(nepochs):\n",
    "        N = len(dataloader)\n",
    "        sum_batch_loss, sum_batch_acc = 0, 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            train_batch(x, model, data, optimizer, criterion)\n",
    "        dataloader = finish_epoch(dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb07e1ac",
   "metadata": {},
   "source": [
    "# FLIM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4865714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convBlock(ni, no, kernel_size=3, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, no, kernel_size=kernel_size, padding='same', bias=False,dilation=dilation),\n",
    "        nn.BatchNorm2d(no),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    \n",
    "class ContrastiveFeatureReducerFLIM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveFeatureReducerFLIM, self).__init__()\n",
    "        \n",
    "        model_path = 'flim-models/model'\n",
    "        architecture_name = 'arch.json'\n",
    "        architecture = utils.load_architecture('%s/%s' % (model_path,architecture_name))\n",
    "        self.encoder = utils.build_model(architecture, input_shape=[3])\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.reducer = nn.Sequential(\n",
    "            convBlock(163,128,1),\n",
    "            nn.Conv2d(128, 16, kernel_size=1, padding='same', bias=False)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        inter_feats = [x]\n",
    "        y = self.encoder.features[0](x)\n",
    "        y = self.encoder.features[1](y)\n",
    "        inter_feats.append(y)\n",
    "        y = self.encoder.features[2](y)\n",
    "        y = self.encoder.features[3](y)\n",
    "        y = self.encoder.features[4](y)\n",
    "        inter_feats.append(y)\n",
    "        y = self.encoder.features[5](y)\n",
    "        y = self.encoder.features[6](y)\n",
    "        y = self.encoder.features[7](y)\n",
    "        inter_feats.append(y)\n",
    "        \n",
    "        y = torch.cat(inter_feats, 1)\n",
    "        \n",
    "        reduced = self.reducer(y)\n",
    "        reduced_x = torch.cat((reduced,x), 1)\n",
    "    \n",
    "        return reduced_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847ab6a",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57a21031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3,padding='same')\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.bs1   = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3,padding='same')\n",
    "        self.bs2   = nn.BatchNorm2d(out_ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.bs2(self.relu(self.conv2(self.bs1(self.relu(self.conv1(x))))))\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=(3,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            enc_ftrs = self.crop(encoder_features[i], x)\n",
    "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, enc_ftrs, x):\n",
    "        _, _, H, W = x.shape\n",
    "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
    "        return enc_ftrs\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs=(3,64,128,256,512,1024), dec_chs=(1024, 512, 256, 128, 64), num_feats_out=1, skipconnect_x=False):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_feats_out, 1)\n",
    "        self.skipconnect_x = skipconnect_x\n",
    "\n",
    "    def forward(self, x, cat_x=False):\n",
    "        out_sz   = (x.shape[2], x.shape[3])\n",
    "        \n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        out      = nn.functional.interpolate(out, out_sz)\n",
    "        if self.skipconnect_x:\n",
    "            out  = torch.cat((x,out), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5da670",
   "metadata": {},
   "source": [
    "# Aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d38bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tmp_dataset(dataset_path, file, ext):\n",
    "    csv_tmp = f\"{dataset_path}/tmp.csv\"\n",
    "    with open(csv_tmp, 'w') as f:\n",
    "        f.write(file)\n",
    "    \n",
    "    dataset = DeepDynamicTreesDataset(dataset_path, 2048, csv=\"tmp.csv\",\n",
    "                                      ext_img=ext[0], ext_label=ext[1],\n",
    "                                      prob_tresh=0.97, radius_adj=10)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc812c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_flim():\n",
    "    return ContrastiveFeatureReducerFLIM().to(device)\n",
    "\n",
    "def init_model_unet():\n",
    "    return UNet(num_feats_out=16, skipconnect_x=True).to(device)\n",
    "\n",
    "\n",
    "def step_flim(dataset):\n",
    "    model = init_model_flim()\n",
    "    \n",
    "    improve_model_for_file(dataset, model, 5)\n",
    "    \n",
    "    x = dataset.imgs[\"tensors\"][0].to(device)\n",
    "    features = model(x)\n",
    "    dice, assd = segment(0, dataset, features)\n",
    "    \n",
    "    return dice, assd\n",
    "\n",
    "def step_unet(dataset):\n",
    "    model = init_model_unet()\n",
    "    \n",
    "    improve_model_for_file(dataset, model, 5)\n",
    "    \n",
    "    x = dataset.imgs[\"tensors\"][0].to(device)\n",
    "    features = model(x)\n",
    "    dice, assd = segment(0, dataset, features)\n",
    "    \n",
    "    return dice, assd\n",
    "    \n",
    "configs = {'U-Net': step_unet,\n",
    "          'FLIM': step_flim}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914eb5c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28040efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e9113c0ada4b22878795ed76d52d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6803915922833286 15.243093344498268\n",
      "0.9807565476103237 1.2480453412931762\n",
      "0.8882307460456826 5.012147172657184\n",
      "0.8495402536735358 3.8100067201075674\n",
      "0.8989894058487526 9.637029423423705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-51cee76ce8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tmp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mdices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-afbe1bc25680>\u001b[0m in \u001b[0;36mstep_unet\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimprove_model_for_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tensors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-83eb3bd4f8e4>\u001b[0m in \u001b[0;36mimprove_model_for_file\u001b[0;34m(dataset, model, nepochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinish_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-83eb3bd4f8e4>\u001b[0m in \u001b[0;36mfinish_epoch\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinish_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-84c4756aeeaa>\u001b[0m in \u001b[0;36mnext_epoch\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading next epoch...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_prob_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_probability_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_epochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-84c4756aeeaa>\u001b[0m in \u001b[0;36mcalculate_probability_map\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_pseudo_markers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-84c4756aeeaa>\u001b[0m in \u001b[0;36mset_pseudo_markers\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskImageToSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsNumPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mbg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskImageToSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsNumPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mfg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfg_seeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mbg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbg_seeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"markers_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fg_seeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg_seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-84c4756aeeaa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskImageToSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsNumPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mbg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskImageToSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsNumPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mfg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfg_seeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mbg_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbg_seeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"markers_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fg_seeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg_seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/ift/PyIFT/pyift/pyift.py\u001b[0m in \u001b[0;36mGetVoxel\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \"\"\"\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pyift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage_GetVoxel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetVoxelSizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"PyObject *\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "datasets = [('datasets/GRABCUT',['ppm', 'pgm']), \n",
    "            ('datasets/gulshan', ['png', 'png']), \n",
    "            ('datasets/andrade',['ppm', 'pgm'])]\n",
    "\n",
    "with open(f\"EXP_{now.strftime('%Y_%m_%d_%H_%M_%S')}.csv\", 'w') as file:\n",
    "    file.write('model; dataset; mean dice; std dice; mean assd; std assd\\n')\n",
    "    \n",
    "    for dataset_path, ext in datasets:\n",
    "        dataset_csv = dataset_path + '/files-all.csv'\n",
    "        file_csv = open(dataset_csv,\"r\")\n",
    "        imgs = [img.strip() for img in file_csv]\n",
    "\n",
    "        for desc, model_eval in configs.items():\n",
    "            dices = []\n",
    "            assds = []\n",
    "\n",
    "            for i in tqdm(range(len(imgs))):\n",
    "                dataset = create_tmp_dataset(dataset_path, imgs[i], ext)\n",
    "                dice, assd = model_eval(dataset)\n",
    "                print(dice,assd)\n",
    "                dices.append(dice)\n",
    "                assds.append(assd)\n",
    "\n",
    "            file.write(f'{desc}; {dataset_path}; {np.mean(dices)}; {np.std(dices)}; {np.mean(assds)}; {np.std(assds)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bea4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f6af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
