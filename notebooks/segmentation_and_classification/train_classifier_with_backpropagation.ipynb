{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flim.experiments import utils, LIDSDataset, ToTensor\n",
    "from flim.models.lcn import LCNCreator\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "import torchmetrics as tm\n",
    "\n",
    "from math import ceil, floor\n",
    "\n",
    "import copy\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a CPU/GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the folder which contains your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/corel\n"
     ]
    }
   ],
   "source": [
    "base_dir = path.join(\"..\", \"data\", \"corel\")\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a feature extractor using FLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load architecture\n",
    "# in this example, the architecure specifies only a feature extractor,\n",
    "# but it could also be a full model\n",
    "architecture = utils.load_architecture(path.join(base_dir, 'archs', 'arch-lids.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and markers\n",
    "images, markers = utils.load_images_and_markers(path.join(base_dir, 'images-and-markers'))\n",
    "# get input shape\n",
    "ncols     = images.shape[1]\n",
    "nrows     = images.shape[2]\n",
    "nchannels = images.shape[3]\n",
    "nclasses  = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building m-norm1\n",
      "Building conv1\n",
      "Building activation1\n",
      "Building pool1\n",
      "Building m-norm2\n",
      "Building conv2\n",
      "Building activation2\n",
      "Building pool2\n"
     ]
    }
   ],
   "source": [
    "# build model and learn convolutional layers with FLIM\n",
    "creator = LCNCreator(architecture, images=images, markers=markers, relabel_markers=True, device=device)\n",
    "creator.build_model()\n",
    "\n",
    "feature_extractor = creator.get_LIDSConvNet().features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: overwrite the weights from another FLIM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model with surrogate weights must have the same architecture and you must inform \n",
    "# the folder which contains its parameters\n",
    "\n",
    "#feature_extractor = utils.load_weights_from_lids_model(feature_extractor, path.join(base_dir, 'param')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feeze the feature extractor to avoid retraining it\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch from train to eval mode\n",
    "feature_extractor.eval()\n",
    "# dry run to find out the number of input features for the classifier\n",
    "ones        = torch.ones(1, nchannels, nrows, ncols, device=device)\n",
    "in_features = feature_extractor(ones).flatten(start_dim=1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifier = nn.Sequential(\n",
    "    nn.Flatten(1),\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, nclasses)\n",
    ")\n",
    "# init weights\n",
    "for layer in clasifier:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_normal_(layer.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(layer.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module(\"features\", feature_extractor)\n",
    "model.add_module(\"classifier\", clasifier)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 100, 100]        --\n",
      "|    └─MarkerBasedNorm2d: 2-1            [-1, 3, 400, 400]         (6)\n",
      "|    └─Conv2d: 2-2                       [-1, 32, 400, 400]        (2,400)\n",
      "|    └─ReLU: 2-3                         [-1, 32, 400, 400]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 200, 200]        --\n",
      "|    └─MarkerBasedNorm2d: 2-5            [-1, 32, 200, 200]        (64)\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 200, 200]        (18,432)\n",
      "|    └─ReLU: 2-7                         [-1, 64, 200, 200]        --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 100, 100]        --\n",
      "├─Sequential: 1-2                        [-1, 6]                   --\n",
      "|    └─Flatten: 2-9                      [-1, 640000]              --\n",
      "|    └─Linear: 2-10                      [-1, 512]                 327,680,512\n",
      "|    └─ReLU: 2-11                        [-1, 512]                 --\n",
      "|    └─Linear: 2-12                      [-1, 6]                   3,078\n",
      "==========================================================================================\n",
      "Total params: 327,704,492\n",
      "Trainable params: 327,683,590\n",
      "Non-trainable params: 20,902\n",
      "Total mult-adds (G): 1.78\n",
      "==========================================================================================\n",
      "Input size (MB): 1.83\n",
      "Forward/backward pass size (MB): 72.03\n",
      "Params size (MB): 1250.09\n",
      "Estimated Total Size (MB): 1323.95\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 100, 100]        --\n",
       "|    └─MarkerBasedNorm2d: 2-1            [-1, 3, 400, 400]         (6)\n",
       "|    └─Conv2d: 2-2                       [-1, 32, 400, 400]        (2,400)\n",
       "|    └─ReLU: 2-3                         [-1, 32, 400, 400]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 32, 200, 200]        --\n",
       "|    └─MarkerBasedNorm2d: 2-5            [-1, 32, 200, 200]        (64)\n",
       "|    └─Conv2d: 2-6                       [-1, 64, 200, 200]        (18,432)\n",
       "|    └─ReLU: 2-7                         [-1, 64, 200, 200]        --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 64, 100, 100]        --\n",
       "├─Sequential: 1-2                        [-1, 6]                   --\n",
       "|    └─Flatten: 2-9                      [-1, 640000]              --\n",
       "|    └─Linear: 2-10                      [-1, 512]                 327,680,512\n",
       "|    └─ReLU: 2-11                        [-1, 512]                 --\n",
       "|    └─Linear: 2-12                      [-1, 6]                   3,078\n",
       "==========================================================================================\n",
       "Total params: 327,704,492\n",
       "Trainable params: 327,683,590\n",
       "Non-trainable params: 20,902\n",
       "Total mult-adds (G): 1.78\n",
       "==========================================================================================\n",
       "Input size (MB): 1.83\n",
       "Forward/backward pass size (MB): 72.03\n",
       "Params size (MB): 1250.09\n",
       "Estimated Total Size (MB): 1323.95\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (nchannels,nrows,ncols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics() -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dictionary of metrics to compute.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"acc\": tm.Accuracy().to(device),\n",
    "        \"kappa\": tm.CohenKappa(num_classes=nclasses).to(device),\n",
    "    }\n",
    "\n",
    "def training_step(model: nn.Module,\n",
    "                  batch_x: Tensor,\n",
    "                  batch_y: Tensor,\n",
    "                  optimizer: optim.Optimizer,\n",
    "                  metrics: dict) -> Tensor:\n",
    "    \"\"\"\n",
    "    One training step over one batch (batch_x, batch_y).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model   : nn.Module\n",
    "        Model to train.\n",
    "    batch_x : torch.Tensor\n",
    "        Input batch.\n",
    "    batch_y : torch.Tensor\n",
    "        Target batch.\n",
    "    optimizer : optim.Optimizer\n",
    "        Optimizer to use.\n",
    "    metrics : dict\n",
    "        Metrics to compute.\n",
    "    Returns\n",
    "    -------\n",
    "    loss : Tensor\n",
    "        Loss computed on the batch.\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch_x)\n",
    "    loss = F.cross_entropy(output, batch_y)\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    for _, metric in metrics.items():\n",
    "        metric(output.softmax(dim=1), batch_y)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def evaluation_step(model: nn.Module, \n",
    "                    batch_x: torch.Tensor,\n",
    "                    batch_y: torch.Tensor,\n",
    "                    metrics: dict) -> Tensor:\n",
    "    \"\"\"\n",
    "    One evaluation step over one batch (batch_x, batch_y).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model   : nn.Module\n",
    "        Model to evaluate.\n",
    "    batch_x : torch.Tensor\n",
    "        Input batch.\n",
    "    batch_y : torch.Tensor\n",
    "        Target batch.\n",
    "    metrics : dict\n",
    "        Metrics to compute.\n",
    "    Returns\n",
    "    -------\n",
    "    loss: Tensor\n",
    "        Loss computed on the batch.\n",
    "    \"\"\"\n",
    "    output = model(batch_x)\n",
    "    loss = F.cross_entropy(output, batch_y)\n",
    "\n",
    "    for _, metric in metrics.items():\n",
    "        metric(output.softmax(dim=1), batch_y)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train set. It should be a folder with images named as 0000{label}_0000{imge_number}.{image_format}\n",
    "# You can create a .txt file with the name of the images in the train set and another file with the name of the images in test set\n",
    "trainset = LIDSDataset(path.join(base_dir, 'dataset'), path.join(base_dir, 'train.txt'), transform=ToTensor())\n",
    "# split train set in train and validation set\n",
    "# consider forcing splits to be stratified\n",
    "trainset, valset = random_split(trainset, [ceil(len(trainset)*0.8), floor(len(trainset)*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, drop_last=False)\n",
    "valloader   = DataLoader(valset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afalcao/miniconda3/envs/FLIM/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "lr      = 0.00001\n",
    "w_decay = 0.1\n",
    "epochs  = 30\n",
    "\n",
    "# set feature extraction in evaluation mode  \n",
    "model.features.eval()\n",
    "\n",
    "# get the trainable parameters\n",
    "params = [param for param in model.parameters() if param.requires_grad]\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(params, lr=lr, weight_decay=w_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, cooldown=3, factor=0.1, verbose=False)\n",
    "# get evaluation metrics      \n",
    "train_metrics = get_metrics()\n",
    "val_metrics   = get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training]\tepoch: 0/29\tloss: 2.512415\tacc: 0.366071\tkappa: 0.212127\n",
      "[validating]\tepoch: 0/29\tloss: 2.183391\tacc: 0.481481\tkappa: 0.343750\n",
      "[training]\tepoch: 1/29\tloss: 0.753515\tacc: 0.549107\tkappa: 0.446196\n",
      "[validating]\tepoch: 1/29\tloss: 1.504442\tacc: 0.555556\tkappa: 0.440414\n",
      "[training]\tepoch: 2/29\tloss: 0.701454\tacc: 0.636905\tkappa: 0.553260\n",
      "[validating]\tepoch: 2/29\tloss: 0.905116\tacc: 0.592593\tkappa: 0.484673\n",
      "[training]\tepoch: 3/29\tloss: 0.275817\tacc: 0.703125\tkappa: 0.634687\n",
      "[validating]\tepoch: 3/29\tloss: 0.969730\tacc: 0.601852\tkappa: 0.500000\n",
      "[training]\tepoch: 4/29\tloss: 0.106598\tacc: 0.753571\tkappa: 0.696911\n",
      "[validating]\tepoch: 4/29\tloss: 0.680701\tacc: 0.637037\tkappa: 0.539185\n",
      "[training]\tepoch: 5/29\tloss: 0.089724\tacc: 0.788690\tkappa: 0.740059\n",
      "[validating]\tepoch: 5/29\tloss: 0.623013\tacc: 0.672840\tkappa: 0.582555\n",
      "[training]\tepoch: 6/29\tloss: 0.022066\tacc: 0.818878\tkappa: 0.777252\n",
      "[validating]\tepoch: 6/29\tloss: 0.630299\tacc: 0.703704\tkappa: 0.621053\n",
      "[training]\tepoch: 7/29\tloss: 0.031669\tacc: 0.840402\tkappa: 0.803778\n",
      "[validating]\tepoch: 7/29\tloss: 0.646244\tacc: 0.717593\tkappa: 0.638816\n",
      "[training]\tepoch: 8/29\tloss: 0.013986\tacc: 0.858135\tkappa: 0.825606\n",
      "[validating]\tepoch: 8/29\tloss: 0.545997\tacc: 0.736625\tkappa: 0.662632\n",
      "[training]\tepoch: 9/29\tloss: 0.006540\tacc: 0.872321\tkappa: 0.843063\n",
      "[validating]\tepoch: 9/29\tloss: 0.558885\tacc: 0.751852\tkappa: 0.681738\n",
      "[training]\tepoch: 10/29\tloss: 0.009019\tacc: 0.883929\tkappa: 0.857344\n",
      "[validating]\tepoch: 10/29\tloss: 0.578660\tacc: 0.764310\tkappa: 0.697406\n",
      "[training]\tepoch: 11/29\tloss: 0.006757\tacc: 0.893601\tkappa: 0.869242\n",
      "[validating]\tepoch: 11/29\tloss: 0.544991\tacc: 0.774691\tkappa: 0.710743\n",
      "[training]\tepoch: 12/29\tloss: 0.003750\tacc: 0.901786\tkappa: 0.879309\n",
      "[validating]\tepoch: 12/29\tloss: 0.550111\tacc: 0.783476\tkappa: 0.722027\n",
      "[training]\tepoch: 13/29\tloss: 0.004071\tacc: 0.908801\tkappa: 0.887936\n",
      "[validating]\tepoch: 13/29\tloss: 0.561296\tacc: 0.791005\tkappa: 0.731698\n",
      "[training]\tepoch: 14/29\tloss: 0.004049\tacc: 0.914881\tkappa: 0.895412\n",
      "[validating]\tepoch: 14/29\tloss: 0.560999\tacc: 0.797531\tkappa: 0.740080\n",
      "[training]\tepoch: 15/29\tloss: 0.004011\tacc: 0.920201\tkappa: 0.901953\n",
      "[validating]\tepoch: 15/29\tloss: 0.554848\tacc: 0.803241\tkappa: 0.747414\n",
      "[training]\tepoch: 16/29\tloss: 0.003413\tacc: 0.924895\tkappa: 0.907724\n",
      "[validating]\tepoch: 16/29\tloss: 0.553991\tacc: 0.808279\tkappa: 0.753884\n",
      "[training]\tepoch: 17/29\tloss: 0.003545\tacc: 0.929067\tkappa: 0.912853\n",
      "[validating]\tepoch: 17/29\tloss: 0.553097\tacc: 0.812757\tkappa: 0.759636\n",
      "[training]\tepoch: 18/29\tloss: 0.003514\tacc: 0.932801\tkappa: 0.917442\n",
      "[validating]\tepoch: 18/29\tloss: 0.552048\tacc: 0.816764\tkappa: 0.764782\n",
      "[training]\tepoch: 19/29\tloss: 0.003469\tacc: 0.936161\tkappa: 0.921572\n",
      "[validating]\tepoch: 19/29\tloss: 0.551152\tacc: 0.820370\tkappa: 0.769414\n",
      "[training]\tepoch: 20/29\tloss: 0.003539\tacc: 0.939201\tkappa: 0.925309\n",
      "[validating]\tepoch: 20/29\tloss: 0.550275\tacc: 0.823633\tkappa: 0.773604\n",
      "[training]\tepoch: 21/29\tloss: 0.003336\tacc: 0.941964\tkappa: 0.928706\n",
      "[validating]\tepoch: 21/29\tloss: 0.549310\tacc: 0.826599\tkappa: 0.777413\n",
      "[training]\tepoch: 22/29\tloss: 0.003370\tacc: 0.944488\tkappa: 0.931807\n",
      "[validating]\tepoch: 22/29\tloss: 0.548512\tacc: 0.829308\tkappa: 0.780891\n",
      "[training]\tepoch: 23/29\tloss: 0.003397\tacc: 0.946801\tkappa: 0.934649\n",
      "[validating]\tepoch: 23/29\tloss: 0.548426\tacc: 0.831790\tkappa: 0.784079\n",
      "[training]\tepoch: 24/29\tloss: 0.003597\tacc: 0.948929\tkappa: 0.937265\n",
      "[validating]\tepoch: 24/29\tloss: 0.548350\tacc: 0.834074\tkappa: 0.787012\n",
      "[training]\tepoch: 25/29\tloss: 0.003353\tacc: 0.950893\tkappa: 0.939678\n",
      "[validating]\tepoch: 25/29\tloss: 0.548257\tacc: 0.836182\tkappa: 0.789720\n",
      "[training]\tepoch: 26/29\tloss: 0.003149\tacc: 0.952712\tkappa: 0.941913\n",
      "[validating]\tepoch: 26/29\tloss: 0.548160\tacc: 0.838134\tkappa: 0.792226\n",
      "[training]\tepoch: 27/29\tloss: 0.003455\tacc: 0.954401\tkappa: 0.943989\n",
      "[validating]\tepoch: 27/29\tloss: 0.548063\tacc: 0.839947\tkappa: 0.794554\n",
      "[training]\tepoch: 28/29\tloss: 0.003274\tacc: 0.955973\tkappa: 0.945921\n",
      "[validating]\tepoch: 28/29\tloss: 0.547976\tacc: 0.841635\tkappa: 0.796721\n",
      "[training]\tepoch: 29/29\tloss: 0.003332\tacc: 0.957440\tkappa: 0.947724\n",
      "[validating]\tepoch: 29/29\tloss: 0.547890\tacc: 0.843210\tkappa: 0.798744\n"
     ]
    }
   ],
   "source": [
    "# save the model with the best validation kappa\n",
    "best_model = None\n",
    "best_kappa = -1\n",
    "\n",
    "# training loop\n",
    "for epoch in range(0, epochs):\n",
    "    # training setp\n",
    "    N = len(trainloader)\n",
    "    train_loss = 0 \n",
    "    for i, data in enumerate(trainloader):\n",
    "        model.classifier.train()\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        loss = training_step(model, inputs, labels, optimizer, train_metrics)\n",
    "        train_loss += loss\n",
    "        print(f\"\\r[training]\\tepoch: {epoch}/{epochs-1}\\titeration: {i}/{N-1}\\tloss: {loss.item():.6f}\", end=\"\")\n",
    "\n",
    "    train_loss = train_loss / N\n",
    "    train_acc = train_metrics['acc'].compute()\n",
    "    train_kappa = train_metrics['kappa'].compute()\n",
    "\n",
    "    print(f\"\\r[training]\\tepoch: {epoch}/{epochs-1}\\tloss: {train_loss.item():.6f}\\tacc: {train_acc:.6f}\\tkappa: {train_kappa:.6f}\")\n",
    "\n",
    "    # validation step\n",
    "    N = len(valloader)\n",
    "    val_loss = 0\n",
    "    for i, data in enumerate(valloader):\n",
    "        with torch.no_grad():\n",
    "            model.classifier.eval()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            loss = evaluation_step(model, inputs, labels, val_metrics)\n",
    "            val_loss += loss\n",
    "            print(f\"\\r[validating]\\tepoch: {epoch}/{epochs-1}\\titeration: {i}/{N-1}\\tloss: {loss.item():.6f}\", end=\"\")\n",
    "\n",
    "    val_loss = val_loss / N\n",
    "    val_acc = val_metrics[\"acc\"].compute()\n",
    "    val_kappa = val_metrics[\"kappa\"].compute()\n",
    "\n",
    "    print(f\"\\r[validating]\\tepoch: {epoch}/{epochs-1}\\tloss: {val_loss.item():.6f}\\tacc: {val_acc:.6f}\\tkappa: {val_kappa:.6f}\")\n",
    "\n",
    "    # save the model if it has the best validation kappa\n",
    "    if epoch == 0 or val_kappa > best_kappa:\n",
    "        best_kappa = val_kappa\n",
    "        best_model = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test set. It should be a folder with images named as 0000{label}_0000{imge_number}.{image_format}\n",
    "# You can create a .txt file with the name of the images in the test set\n",
    "testset    = LIDSDataset(path.join(base_dir, 'dataset'), path.join(base_dir, 'test.txt'), transform=ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[testing] acc: 0.921296\tkappa: 0.90372894391822815\n"
     ]
    }
   ],
   "source": [
    "# get evalutation metrics\n",
    "test_metrics = get_metrics()\n",
    "\n",
    "# set model in evaluation mode\n",
    "model.load_state_dict(best_model, )\n",
    "model.eval()\n",
    "\n",
    "# testing loop\n",
    "N = len(testloader)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        loss = evaluation_step(model, inputs, labels, test_metrics)\n",
    "        print(f\"\\r[testing]\\titeration: {i}/{N-1}\\tloss: {loss.item()}\", end=\"\")\n",
    "\n",
    "test_acc = test_metrics[\"acc\"].compute()\n",
    "test_kappa = test_metrics[\"kappa\"].compute()\n",
    "\n",
    "print(f\"\\r[testing] acc: {test_acc:.6f}\\tkappa: {test_kappa:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate a SVM classifier using your feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train SVM\n",
      "Fitting SVM...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "svm = utils.train_svm(feature_extractor, trainset, batch_size=32, max_iter=10000, C=1e2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "##################################################\n",
      "\u001b[33mAcc\u001b[0m : \u001b[1m\u001b[34m0.912037\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[33mF1-score\u001b[0m : \u001b[1m\u001b[34m0.912215\u001b[0m\n",
      "--------------------------------------------------\n",
      "Accuracy 0.9074074074074074 0.8666666666666667 1.0 0.95 0.896551724137931 0.9024390243902439\n",
      "--------------------------------------------------\n",
      "Precision: 0.9607843137254902 0.9285714285714286 0.9310344827586207 0.9047619047619048 0.8125 0.9024390243902439\n",
      "Recall: 0.9074074074074074 0.8666666666666667 1.0 0.95 0.896551724137931 0.9024390243902439\n",
      "F-score: 0.9333333333333333 0.896551724137931 0.9642857142857143 0.9268292682926829 0.8524590163934426 0.9024390243902439\n",
      "--------------------------------------------------\n",
      "W-Precision: 0.9141839646139426\n",
      "W-Recall: 0.9120370370370371\n",
      "W-F-score: 0.9122149940425216\n",
      "--------------------------------------------------\n",
      "Kappa 0.892565445026178\n",
      "--------------------------------------------------\n",
      "Suport 54 45 27 20 29 41\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "utils.validate_svm(feature_extractor, svm, testset, batch_size=32, device=device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddcd6092431b27da76678c78100b28c2416c7a18b759e433950fb611764dce11"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
